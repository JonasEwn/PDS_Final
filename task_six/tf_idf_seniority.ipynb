{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a7d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "#from preprocessing.preprocessing_csv import Preprocessing_CSV_Seniority\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from preprocessing.preprocessing_json import Preprocessing_JSON_annotated_Seniority\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from imblearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2fcde5",
   "metadata": {},
   "source": [
    "#### Preprocessing CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd2f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing_CSV():\n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self.df: pd.DataFrame | None = None\n",
    "\n",
    "        # Label and Text\n",
    "        self.X: pd.Series = None\n",
    "        self.y: pd.Series = None\n",
    "\n",
    "        # Optional: keep raw versions too\n",
    "        self.X_raw: pd.Series | None = None\n",
    "        self.y_raw: pd.Series | None = None\n",
    "\n",
    "        self.read_csv()\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"Lowercase, strip, replace - and / with spaces.\"\"\"\n",
    "        return str(text).lower().strip().replace(\"-\", \" \").replace(\"/\", \" \")\n",
    "\n",
    "    def read_csv(self):\n",
    "        \"\"\"Reads CSV and exposes X (cleaned text) and y (raw text labels).\"\"\"\n",
    "        self.df = pd.read_csv(self.file_path)\n",
    "\n",
    "        required_cols = {\"text\", \"label\"}\n",
    "        if not required_cols.issubset(self.df.columns):\n",
    "            raise ValueError(\"Wrong file mate :( Expected columns: text, label\")\n",
    "\n",
    "        # Raw\n",
    "        self.X_raw = self.df[\"text\"].astype(str)\n",
    "        self.y_raw = self.df[\"label\"].astype(str)\n",
    "\n",
    "        # Cleaned + labels as strings\n",
    "        self.X = self.X_raw.apply(self.clean_text)\n",
    "        self.y = self.y_raw\n",
    "\n",
    "    def label_distribution(self) -> pd.Series:\n",
    "        \"\"\"Quick check of label counts.\"\"\"\n",
    "        if self.y is None:\n",
    "            return pd.Series(dtype=int)\n",
    "        return self.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb58112",
   "metadata": {},
   "source": [
    "#### Preprocessin JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing_JSON_annotated_Seniority:\n",
    "    \"\"\"\n",
    "    Loads an annotated JSON file (list of persons, each a list of jobs).\n",
    "    Keeps ONLY the latest ACTIVE job per person (by startDate).\n",
    "    Returns:\n",
    "      - self.X: pd.Series of cleaned positions (text)\n",
    "      - self.y: pd.Series of raw string labels (seniority)  # NOT encoded\n",
    "      - self.df: DataFrame with columns [\"text\", \"label\"]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        self.df: pd.DataFrame | None = None\n",
    "        self.X: pd.Series | None = None\n",
    "        self.y: pd.Series | None = None\n",
    "\n",
    "        self.read_json()\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_year_month(s):\n",
    "        \"\"\"Expects 'YYYY-MM' -> (year, month) or None.\"\"\"\n",
    "        if not isinstance(s, str) or len(s) < 7:\n",
    "            return None\n",
    "        try:\n",
    "            year, month = s.split(\"-\")\n",
    "            return int(year), int(month)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        return str(text).lower().strip().replace(\"-\", \" \").replace(\"/\", \" \")\n",
    "\n",
    "    def read_json(self):\n",
    "        with open(self.path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        rows = []\n",
    "\n",
    "        for person_jobs in data:\n",
    "            if not isinstance(person_jobs, list):\n",
    "                continue\n",
    "\n",
    "            active_jobs = []\n",
    "            for job in person_jobs:\n",
    "                if not isinstance(job, dict):\n",
    "                    continue\n",
    "                if job.get(\"status\") != \"ACTIVE\":\n",
    "                    continue\n",
    "\n",
    "                start = self._parse_year_month(job.get(\"startDate\"))\n",
    "                if start is None:\n",
    "                    continue\n",
    "\n",
    "                active_jobs.append((start, job))\n",
    "\n",
    "            if not active_jobs:\n",
    "                continue\n",
    "\n",
    "            _, job = max(active_jobs, key=lambda x: x[0])\n",
    "\n",
    "            position = job.get(\"position\")\n",
    "            seniority = job.get(\"seniority\")\n",
    "\n",
    "            if not position or not seniority:\n",
    "                continue\n",
    "\n",
    "            rows.append(\n",
    "                {\"text\": self.clean_text(position), \"label\": str(seniority)}\n",
    "            )\n",
    "\n",
    "        self.df = pd.DataFrame(rows)\n",
    "        if self.df.empty:\n",
    "            raise ValueError(\"No valid samples found in JSON\")\n",
    "\n",
    "        self.X = self.df[\"text\"].astype(str)\n",
    "        self.y = self.df[\"label\"].astype(str)\n",
    "\n",
    "        print(f\"[JSON] Loaded {len(self.df)} samples from {self.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c22db",
   "metadata": {},
   "source": [
    "#### Pipeline:\n",
    "\n",
    "1. Load and Prepare CSV Data\n",
    "2. Load and Prepare not-annotated.json data\n",
    "3. Concatenate and Train-Test Split\n",
    "4. Bow and Logistic Regression with Hyperparam Search and 5 Fold CV\n",
    "5. Test on test set\n",
    "6. Test on annotated.json -> maybe with .predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a605f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and Prepare CSV Data\n",
    "data = Preprocessing_CSV(\n",
    "    \"/Users/jonas/Documents/Master_Vorlesungen/Semester_02/Practical Data Science/Final/PDS_Final/data/seniority-v2.csv\"\n",
    ")\n",
    "\n",
    "X = data.X\n",
    "y = data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7372b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load and Prepare not-annotated.json Data\n",
    "not_annotated_data = pd.read_csv(\"/Users/jonas/Documents/Master_Vorlesungen/Semester_02/Practical Data Science/Final/PDS_Final/data/labeled_not_annotated.csv\")\n",
    "X_not_annotated = not_annotated_data[\"position\"].astype(str).apply(data.clean_text)\n",
    "y_not_annotated = not_annotated_data[\"seniority\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336a8482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined X: (9732,)\n",
      "Combined y: (9732,)\n",
      "Unknown labels encoded as -1: 0\n",
      "Senior          3898\n",
      "Lead            3547\n",
      "Director         984\n",
      "Management       815\n",
      "Junior           476\n",
      "Professional      12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. Concatenate and Train/Test split\n",
    "X_concat = pd.concat([X, X_not_annotated], ignore_index=True)\n",
    "y_concat = pd.concat([y, y_not_annotated], ignore_index=True)\n",
    "\n",
    "ordinal_labels = [\"Junior\", \"Professional\", \"Senior\", \"Lead\", \"Management\", \"Director\"]\n",
    "encoder = OrdinalEncoder(categories=[ordinal_labels], handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "y_encoded = encoder.fit_transform(y_concat.values.reshape(-1,1)).flatten()\n",
    "\n",
    "print(\"Combined X:\", X_concat.shape)\n",
    "print(\"Combined y:\", y_encoded.shape)\n",
    "print(\"Unknown labels encoded as -1:\", (y_encoded == -1).sum())\n",
    "print(y_concat.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be151ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_concat, y_encoded, test_size=0.2, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b83215e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best params: {'clf__C': 10, 'clf__class_weight': None, 'clf__solver': 'liblinear', 'tfidf__max_df': 0.9, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1), 'tfidf__sublinear_tf': False}\n",
      "Best CV score: 0.8601119687211339\n"
     ]
    }
   ],
   "source": [
    "# 4. BOW and Logistic Regression with Hyperparam Search and 5 fold CV\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    (\"ros\", RandomOverSampler(random_state=123)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    \"tfidf__min_df\": [1, 2, 3],\n",
    "    \"tfidf__max_df\": [0.9, 0.95, 1.0],\n",
    "    \"tfidf__sublinear_tf\": [True, False],\n",
    "    \"tfidf__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"clf__C\": [0.1, 1, 10],\n",
    "    \"clf__solver\": [\"liblinear\"],\n",
    "    \"clf__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=parameters,\n",
    "    cv=cv,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22b8d8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9542886492039034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Junior       0.90      0.86      0.88        95\n",
      "Professional       0.00      0.00      0.00         2\n",
      "      Senior       0.97      0.95      0.96       780\n",
      "        Lead       0.96      0.98      0.97       710\n",
      "  Management       0.87      0.89      0.88       163\n",
      "    Director       0.97      0.98      0.98       197\n",
      "\n",
      "    accuracy                           0.95      1947\n",
      "   macro avg       0.78      0.78      0.78      1947\n",
      "weighted avg       0.95      0.95      0.95      1947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Test on test-set\n",
    "\n",
    "csv_prediction = best_model.predict(X_test) # Auch predict_proba() probieren\n",
    "print(\"Accuracy:\", accuracy_score(y_test, csv_prediction))\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        csv_prediction,\n",
    "        target_names=ordinal_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baadf65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[JSON] Loaded 457 samples from /Users/jonas/Documents/Master_Vorlesungen/Semester_02/Practical Data Science/Final/PDS_Final/data/linkedin-cvs-annotated.json\n"
     ]
    }
   ],
   "source": [
    "# 6. Test on annotated.json\n",
    "\n",
    "annotated_json_data = Preprocessing_JSON_annotated_Seniority(\n",
    "    \"/Users/jonas/Documents/Master_Vorlesungen/Semester_02/Practical Data Science/Final/PDS_Final/data/linkedin-cvs-annotated.json\",\n",
    ")\n",
    "\n",
    "X_annotated = annotated_json_data.X\n",
    "y_annotated = annotated_json_data.y\n",
    "\n",
    "y_annotated_encoded = encoder.transform(y_annotated.values.reshape(-1,1)).flatten()\n",
    "\n",
    "\n",
    "#X_annotated_bow = bow.transform(X_annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16432ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on annotated.json: 0.45076586433260396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Junior       0.13      0.40      0.20        10\n",
      "Professional       0.20      0.02      0.04       154\n",
      "      Senior       0.23      0.85      0.36        39\n",
      "        Lead       0.46      0.63      0.53        97\n",
      "  Management       0.85      0.62      0.72       133\n",
      "    Director       0.56      0.92      0.70        24\n",
      "\n",
      "    accuracy                           0.45       457\n",
      "   macro avg       0.41      0.57      0.42       457\n",
      "weighted avg       0.46      0.45      0.41       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_annotated = best_model.predict(X_annotated)\n",
    "\n",
    "print(f\"Accuracy on annotated.json: {accuracy_score(y_annotated_encoded, predict_annotated)}\")\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_annotated_encoded,\n",
    "        predict_annotated,\n",
    "        target_names=ordinal_labels,\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977e3988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Junior  Professional  Senior  Lead  Management  Director\n",
      "Junior             4             0       4     2           0         0\n",
      "Professional      22             3      65    55           9         0\n",
      "Senior             1             0      33     2           2         1\n",
      "Lead               2             0      31    61           3         0\n",
      "Management         1            12       9    12          83        16\n",
      "Director           0             0       1     0           1        22\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_annotated_encoded, predict_annotated)\n",
    "labels = encoder.categories[0]\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(df_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0134e36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on annotated.json (thr=0.65): 0.5492341356673961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Junior       0.17      0.40      0.24        10\n",
      "Professional       0.54      0.43      0.48       154\n",
      "      Senior       0.26      0.79      0.39        39\n",
      "        Lead       0.83      0.46      0.60        97\n",
      "  Management       0.85      0.62      0.72       133\n",
      "    Director       0.56      0.92      0.70        24\n",
      "\n",
      "    accuracy                           0.55       457\n",
      "   macro avg       0.54      0.60      0.52       457\n",
      "weighted avg       0.66      0.55      0.57       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Use Probability to improve\n",
    "\n",
    "\n",
    "def predict_with_threshold(pipe, X_text, encoder, ordinal_labels, thr=0.55):\n",
    "    \"\"\"\n",
    "    If predicted class âˆˆ {Junior, Senior, Lead} but proba < thr -> set to Professional.\n",
    "    Returns encoded predictions.\n",
    "    \"\"\"\n",
    "    proba = pipe.predict_proba(X_text)\n",
    "    pred = pipe.predict(X_text).copy()  # encoded labels\n",
    "\n",
    "    # Mapping label name -> encoded id based on the encoder's fixed order\n",
    "    name2id = {name: i for i, name in enumerate(ordinal_labels)}\n",
    "\n",
    "    target_ids = {name2id[\"Junior\"], name2id[\"Senior\"], name2id[\"Lead\"]}\n",
    "    prof_id = name2id[\"Professional\"]\n",
    "\n",
    "    # proba columns correspond to clf.classes_ (NOT necessarily 0..5 order)\n",
    "    clf = pipe.named_steps[\"clf\"]\n",
    "    classid_to_col = {cid: j for j, cid in enumerate(clf.classes_)}\n",
    "\n",
    "    for i, cid in enumerate(pred):\n",
    "        if cid in target_ids:\n",
    "            p = proba[i, classid_to_col[cid]]\n",
    "            if p < thr:\n",
    "                pred[i] = prof_id\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "# ---- Your annotated.json evaluation with threshold ----\n",
    "thr = 0.65  # try 0.5, 0.55, 0.6\n",
    "\n",
    "predict_annotated_thr = predict_with_threshold(\n",
    "    best_model,\n",
    "    X_annotated,\n",
    "    encoder,\n",
    "    ordinal_labels,\n",
    "    thr=thr\n",
    ")\n",
    "\n",
    "print(f\"Accuracy on annotated.json (thr={thr}):\",\n",
    "      accuracy_score(y_annotated_encoded, predict_annotated_thr))\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_annotated_encoded,\n",
    "        predict_annotated_thr,\n",
    "        target_names=ordinal_labels,\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0fa54f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 macro F1: 0.4301632946051403\n",
      "0.5 macro F1: 0.4535625723962092\n",
      "0.55 macro F1: 0.4642396949157666\n",
      "0.6 macro F1: 0.47971184398077976\n",
      "0.65 macro F1: 0.5203249254108341\n"
     ]
    }
   ],
   "source": [
    "for thr in [0.4, 0.5, 0.55, 0.6, 0.65]:\n",
    "    pred_thr = predict_with_threshold(best_model, X_annotated, encoder, ordinal_labels, thr=thr)\n",
    "    print(thr, \"macro F1:\", f1_score(y_annotated_encoded, pred_thr, average=\"macro\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
