{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b231ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "#from preprocessing.preprocessing_csv import Preprocessing_CSV\n",
    "#from preprocessing.preprocessing_department_json import Preprocessing_JSON_annotated_Department\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from imblearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b1082",
   "metadata": {},
   "source": [
    "#### Preprocessing CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing_CSV():\n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self.df: pd.DataFrame | None = None\n",
    "\n",
    "        # Label and Text\n",
    "        self.X: pd.Series = None\n",
    "        self.y: pd.Series = None\n",
    "\n",
    "        # Optional: keep raw versions too\n",
    "        self.X_raw: pd.Series | None = None\n",
    "        self.y_raw: pd.Series | None = None\n",
    "\n",
    "        self.read_csv()\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"Lowercase, strip, replace - and / with spaces.\"\"\"\n",
    "        return str(text).lower().strip().replace(\"-\", \" \").replace(\"/\", \" \")\n",
    "\n",
    "    def read_csv(self):\n",
    "        \"\"\"Reads CSV and exposes X (cleaned text) and y (raw text labels).\"\"\"\n",
    "        self.df = pd.read_csv(self.file_path)\n",
    "\n",
    "        required_cols = {\"text\", \"label\"}\n",
    "        if not required_cols.issubset(self.df.columns):\n",
    "            raise ValueError(\"Wrong file mate :( Expected columns: text, label\")\n",
    "\n",
    "        # Raw\n",
    "        self.X_raw = self.df[\"text\"].astype(str)\n",
    "        self.y_raw = self.df[\"label\"].astype(str)\n",
    "\n",
    "        # Cleaned + labels as strings\n",
    "        self.X = self.X_raw.apply(self.clean_text)\n",
    "        self.y = self.y_raw\n",
    "\n",
    "    def label_distribution(self) -> pd.Series:\n",
    "        \"\"\"Quick check of label counts.\"\"\"\n",
    "        if self.y is None:\n",
    "            return pd.Series(dtype=int)\n",
    "        return self.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36ca4c",
   "metadata": {},
   "source": [
    "#### Preprocessin JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a331175",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing_JSON_annotated_Department:\n",
    "    \"\"\"\n",
    "    Loads an annotated JSON file (list of persons, each a list of jobs).\n",
    "    Keeps ONLY the latest ACTIVE job per person (by startDate).\n",
    "\n",
    "    Returns:\n",
    "      - self.X: pd.Series of cleaned positions (text)\n",
    "      - self.y: pd.Series of raw string labels (department)  # NOT encoded\n",
    "      - self.df: DataFrame with columns [\"text\", \"label\"]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        self.df: pd.DataFrame | None = None\n",
    "        self.X: pd.Series | None = None\n",
    "        self.y: pd.Series | None = None\n",
    "\n",
    "        self.read_json()\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_year_month(s):\n",
    "        \"\"\"Expects 'YYYY-MM' -> (year, month) or None.\"\"\"\n",
    "        if not isinstance(s, str) or len(s) < 7:\n",
    "            return None\n",
    "        try:\n",
    "            year, month = s.split(\"-\")\n",
    "            return int(year), int(month)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        return str(text).lower().strip().replace(\"-\", \" \").replace(\"/\", \" \")\n",
    "\n",
    "    def read_json(self):\n",
    "        with open(self.path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        rows = []\n",
    "\n",
    "        for person_jobs in data:\n",
    "            if not isinstance(person_jobs, list):\n",
    "                continue\n",
    "\n",
    "            active_jobs = []\n",
    "            for job in person_jobs:\n",
    "                if not isinstance(job, dict):\n",
    "                    continue\n",
    "                if job.get(\"status\") != \"ACTIVE\":\n",
    "                    continue\n",
    "\n",
    "                start = self._parse_year_month(job.get(\"startDate\"))\n",
    "                if start is None:\n",
    "                    continue\n",
    "\n",
    "                active_jobs.append((start, job))\n",
    "\n",
    "            if not active_jobs:\n",
    "                continue\n",
    "\n",
    "            # Latest ACTIVE job\n",
    "            _, job = max(active_jobs, key=lambda x: x[0])\n",
    "\n",
    "            position = job.get(\"position\")\n",
    "            department = job.get(\"department\")\n",
    "\n",
    "            if not position or not department:\n",
    "                continue\n",
    "\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"text\": self.clean_text(position),\n",
    "                    \"label\": str(department)\n",
    "                }\n",
    "            )\n",
    "\n",
    "        self.df = pd.DataFrame(rows)\n",
    "\n",
    "        if self.df.empty:\n",
    "            raise ValueError(\"No valid samples found in JSON\")\n",
    "\n",
    "        # Output as raw strings (NOT encoded)\n",
    "        self.X = self.df[\"text\"].astype(str)\n",
    "        self.y = self.df[\"label\"].astype(str)\n",
    "\n",
    "        print(f\"[JSON-Department] Loaded {len(self.df)} samples from {self.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca1521",
   "metadata": {},
   "source": [
    "#### Pipeline:\n",
    "\n",
    "1. Load and Prepare CSV Data\n",
    "2. Load and Prepare not-annotated.json data\n",
    "3. Concatenate and Train-Test Split\n",
    "4. Bow and Logistic Regression with Hyperparam Search and 5 Fold CV\n",
    "5. Test on test set\n",
    "6. Test on annotated.json -> maybe with .predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25eb3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and Prepare CSV Data\n",
    "data = Preprocessing_CSV(\n",
    "    \"/Users/jonas/Documents/Master_Vorlesungen/Semester_02/Practical Data Science/Final/PDS_Final/data/department-v2.csv\"\n",
    ")\n",
    "\n",
    "X = data.X\n",
    "y = data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25218202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load and Prepare not-annotated.json Data\n",
    "not_annotated_data = pd.read_csv(\"/Users/jonas/Documents/Master_Vorlesungen/Semester_02/Practical Data Science/Final/PDS_Final/data/seniority_with_departments.csv\")\n",
    "X_not_annotated = not_annotated_data[\"position\"].astype(str).apply(data.clean_text)\n",
    "y_not_annotated = not_annotated_data[\"department\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba0173dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined X: (10449,)\n",
      "Combined y: (10449,)\n",
      "Classes: ['Administrative' 'Business Development' 'Consulting' 'Customer Support'\n",
      " 'Human Resources' 'Information Technology' 'Marketing' 'Other'\n",
      " 'Project Management' 'Purchasing' 'Sales']\n",
      "Marketing                 4307\n",
      "Sales                     3351\n",
      "Information Technology    1327\n",
      "Business Development       640\n",
      "Project Management         214\n",
      "Other                      210\n",
      "Consulting                 178\n",
      "Administrative              89\n",
      "Customer Support            47\n",
      "Purchasing                  45\n",
      "Human Resources             41\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. Concatenate and Train/Test split\n",
    "X_concat = pd.concat([X, X_not_annotated], ignore_index=True)\n",
    "y_concat = pd.concat([y, y_not_annotated], ignore_index=True)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y_concat)\n",
    "\n",
    "print(\"Combined X:\", X_concat.shape)\n",
    "print(\"Combined y:\", y_encoded.shape)\n",
    "print(\"Classes:\", encoder.classes_)\n",
    "print(y_concat.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3633be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_concat, y_encoded, test_size=0.2, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c389d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best params: {'clf__C': 10, 'clf__class_weight': None, 'clf__solver': 'liblinear', 'tfidf__max_df': 0.9, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2), 'tfidf__sublinear_tf': True}\n",
      "Best CV score: 0.8442779405319\n"
     ]
    }
   ],
   "source": [
    "# 4. BOW and Logistic Regression with Hyperparam Search and 5 fold CV\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    (\"ros\", RandomOverSampler(random_state=123)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    \"tfidf__min_df\": [1, 2, 3],\n",
    "    \"tfidf__max_df\": [0.9, 0.95, 1.0],\n",
    "    \"tfidf__sublinear_tf\": [True, False],\n",
    "    \"tfidf__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"clf__C\": [0.1, 1, 10],\n",
    "    \"clf__solver\": [\"liblinear\"],\n",
    "    \"clf__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=parameters,\n",
    "    cv=cv,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7904df7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9583732057416268\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative       0.75      1.00      0.86        18\n",
      "  Business Development       0.95      0.97      0.96       128\n",
      "            Consulting       0.80      0.92      0.86        36\n",
      "      Customer Support       0.83      0.56      0.67         9\n",
      "       Human Resources       0.75      0.75      0.75         8\n",
      "Information Technology       0.92      0.96      0.94       265\n",
      "             Marketing       1.00      0.97      0.98       862\n",
      "                 Other       0.83      0.69      0.75        42\n",
      "    Project Management       0.81      0.91      0.86        43\n",
      "            Purchasing       1.00      0.89      0.94         9\n",
      "                 Sales       0.96      0.97      0.97       670\n",
      "\n",
      "              accuracy                           0.96      2090\n",
      "             macro avg       0.87      0.87      0.87      2090\n",
      "          weighted avg       0.96      0.96      0.96      2090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Test on test-set\n",
    "\n",
    "csv_prediction = best_model.predict(X_test) # Auch predict_proba() probieren\n",
    "print(\"Accuracy:\", accuracy_score(y_test, csv_prediction))\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        csv_prediction,\n",
    "        target_names=encoder.classes_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0991c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[JSON-Department] Loaded 457 samples from /Users/jonas/Documents/Master_Vorlesungen/Semester_02/Practical Data Science/Final/PDS_Final/data/linkedin-cvs-annotated.json\n"
     ]
    }
   ],
   "source": [
    "# 6. Test on annotated.json\n",
    "\n",
    "annotated_json_data = Preprocessing_JSON_annotated_Department(\n",
    "    \"/Users/jonas/Documents/Master_Vorlesungen/Semester_02/Practical Data Science/Final/PDS_Final/data/linkedin-cvs-annotated.json\",\n",
    ")\n",
    "\n",
    "X_annotated = annotated_json_data.X\n",
    "y_annotated = annotated_json_data.y\n",
    "\n",
    "y_annotated_encoded = encoder.transform(y_annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "702fb733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on annotated.json: 0.5317286652078774\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative       0.20      0.10      0.13        10\n",
      "  Business Development       0.30      0.38      0.33        16\n",
      "            Consulting       0.88      0.56      0.68        27\n",
      "      Customer Support       1.00      0.17      0.29         6\n",
      "       Human Resources       0.73      0.50      0.59        16\n",
      "Information Technology       0.40      0.44      0.42        52\n",
      "             Marketing       0.34      0.53      0.42        19\n",
      "                 Other       0.72      0.55      0.62       232\n",
      "    Project Management       0.54      0.50      0.52        30\n",
      "            Purchasing       0.78      0.58      0.67        12\n",
      "                 Sales       0.29      0.78      0.42        37\n",
      "\n",
      "              accuracy                           0.53       457\n",
      "             macro avg       0.56      0.46      0.46       457\n",
      "          weighted avg       0.61      0.53      0.55       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_annotated = best_model.predict(X_annotated)\n",
    "\n",
    "print(f\"Accuracy on annotated.json: {accuracy_score(y_annotated_encoded, predict_annotated)}\")\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_annotated_encoded,\n",
    "        predict_annotated,\n",
    "        target_names=encoder.classes_,\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c331d465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  1   0   0   0   0   2   1   0   0   0   6]\n",
      " [  0   6   0   0   0   0   0   9   1   0   0]\n",
      " [  0   2  15   0   2   1   1   3   2   0   1]\n",
      " [  0   0   0   1   0   5   0   0   0   0   0]\n",
      " [  0   1   0   0   8   0   0   4   0   0   3]\n",
      " [  0   2   0   0   0  23   1  19   3   0   4]\n",
      " [  0   0   0   0   0   2  10   4   0   0   3]\n",
      " [  4   9   2   0   1  20  11 128   5   2  50]\n",
      " [  0   0   0   0   0   2   2   7  15   0   4]\n",
      " [  0   0   0   0   0   2   2   0   0   7   1]\n",
      " [  0   0   0   0   0   0   1   5   2   0  29]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Confusion Matrix\\n{confusion_matrix(y_annotated_encoded, predict_annotated)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
