{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f68dea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from preprocessing.preprocessing_csv import Preprocessing_CSV_Seniority\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from preprocessing.preprocessing_json import Preprocessing_JSON_Seniority\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a141ef14",
   "metadata": {},
   "source": [
    "#### CSV Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "575e5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing_CSV_Seniority():\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.df: pd.DataFrame = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.y_str = None\n",
    "\n",
    "        # Da Labels eine Ordnung haben OrdinalEncoder anstatten LabelEncoder\n",
    "        #self.label_encoder = LabelEncoder()\n",
    "        self.ordninal_labels = [\n",
    "            \"Junior\",\n",
    "            #\"Professional\",\n",
    "            \"Senior\",\n",
    "            \"Lead\",\n",
    "            \"Management\",\n",
    "            \"Director\"\n",
    "        ]\n",
    "        self.label_encoder = OrdinalEncoder(categories=[self.ordninal_labels],\n",
    "                                            handle_unknown=\"use_encoded_value\",\n",
    "                                            unknown_value=-1)\n",
    "\n",
    "        self.read_csv()\n",
    "\n",
    "    def clean_text(self, text: str):\n",
    "        \"\"\"\n",
    "        Removes - and / and replaces with <space>\n",
    "        \"\"\"\n",
    "        text = text.lower().strip().replace(\"-\", \" \").replace(\"/\", \" \")\n",
    "        return text\n",
    "\n",
    "    def read_csv(self):\n",
    "        \"\"\"\n",
    "        Reads CSV file and saves them in class properties\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(self.file_path)\n",
    "\n",
    "        # Check if correct file is given\n",
    "        requiered_cols = {\"text\", \"label\"}\n",
    "        if not requiered_cols.issubset(self.df.columns):\n",
    "            raise ValueError(\n",
    "                f\"Wrong file mate :(\"\n",
    "            )\n",
    "\n",
    "        self.X = self.df[\"text\"].astype(str).apply(self.clean_text)\n",
    "\n",
    "        # Für OrdinalEncoder\n",
    "        labels = self.df[\"label\"].values.reshape(-1,1)\n",
    "        self.y = self.label_encoder.fit_transform(labels).flatten()\n",
    "\n",
    "        # Für LabelEncoder\n",
    "        #self.y_str = self.df[\"label\"].astype(str)\n",
    "        #self.y = self.label_encoder.fit_transform(self.y_str)\n",
    "        #self.X = self.df[\"text\"]\n",
    "\n",
    "    def labels(self):\n",
    "        \"\"\"\n",
    "        Just quick check, can be removed\n",
    "        \"\"\"\n",
    "        return {\n",
    "            i: label for i, label in enumerate(self.label_encoder.categories_[0])\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60539d69",
   "metadata": {},
   "source": [
    "#### JSON class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5ac4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "class Preprocessing_JSON_Seniority:\n",
    "    \"\"\"\n",
    "    JSON preprocessing ONLY (no prediction logic).\n",
    "\n",
    "    Output (analog zur CSV-Pipeline):\n",
    "        self.df         -> pd.DataFrame (text, label)\n",
    "        self.X          -> pd.Series (cleaned text)\n",
    "        self.y          -> np.ndarray (ordinal labels, incl. Professional)\n",
    "        self.y_reduced  -> np.ndarray (ordinal labels, Professional merged into Junior)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, json_path: str):\n",
    "        self.json_path = json_path\n",
    "\n",
    "        # Full ordinal scale (ground truth)\n",
    "        self.ordinal_labels = [\n",
    "            \"Junior\",\n",
    "            \"Professional\",\n",
    "            \"Senior\",\n",
    "            \"Lead\",\n",
    "            \"Management\",\n",
    "            \"Director\"\n",
    "        ]\n",
    "\n",
    "        self.label_encoder = OrdinalEncoder(\n",
    "            categories=[self.ordinal_labels],\n",
    "            handle_unknown=\"use_encoded_value\",\n",
    "            unknown_value=-1\n",
    "        )\n",
    "\n",
    "        self.df: pd.DataFrame = None\n",
    "        self.X: pd.Series = None\n",
    "        self.y: np.ndarray = None\n",
    "        self.y_reduced: np.ndarray = None\n",
    "\n",
    "        self._read_json()\n",
    "\n",
    "    # ----------------------------\n",
    "    # Helpers\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def _parse_year_month(s):\n",
    "        \"\"\"Expects 'YYYY-MM'. Returns (year, month) or None.\"\"\"\n",
    "        if not isinstance(s, str) or len(s) < 7:\n",
    "            return None\n",
    "        try:\n",
    "            year, month = s.split(\"-\")\n",
    "            return int(year), int(month)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        return str(text).lower().strip().replace(\"-\", \" \").replace(\"/\", \" \")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Core preprocessing\n",
    "    # ----------------------------\n",
    "    def _read_json(self):\n",
    "        with open(self.json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        rows = []\n",
    "\n",
    "        for person in data:\n",
    "            active_jobs = []\n",
    "\n",
    "            for job in person:\n",
    "                # Rule 1: only ACTIVE jobs\n",
    "                if job.get(\"status\") != \"ACTIVE\":\n",
    "                    continue\n",
    "\n",
    "                start = self._parse_year_month(job.get(\"startDate\"))\n",
    "                if start is None:\n",
    "                    continue\n",
    "\n",
    "                active_jobs.append((start, job))\n",
    "\n",
    "            # Rule 2: no ACTIVE job → skip person\n",
    "            if not active_jobs:\n",
    "                continue\n",
    "\n",
    "            # Rule 3: newest ACTIVE job wins\n",
    "            _, job = max(active_jobs, key=lambda x: x[0])\n",
    "\n",
    "            position = job.get(\"position\")\n",
    "            seniority = job.get(\"seniority\")\n",
    "\n",
    "            if not position or not seniority:\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                \"text\": self.clean_text(position),\n",
    "                \"label\": seniority\n",
    "            })\n",
    "\n",
    "        self.df = pd.DataFrame(rows)\n",
    "\n",
    "        if self.df.empty:\n",
    "            raise ValueError(\"No valid samples found in JSON\")\n",
    "\n",
    "        # Output analog zur CSV pipeline\n",
    "        self.X = self.df[\"text\"]\n",
    "\n",
    "        # ---- Full ordinal encoding (WITH Professional) ----\n",
    "        self.y = self.label_encoder.fit_transform(\n",
    "            self.df[\"label\"].values.reshape(-1, 1)\n",
    "        ).flatten()\n",
    "\n",
    "        # ---- Reduced ordinal encoding (Professional → Junior) ----\n",
    "        # Mapping indices:\n",
    "        # Junior=0, Professional=1, Senior=2, Lead=3, Management=4, Director=5\n",
    "        self.y_reduced = np.where(\n",
    "            self.y <= 1,        # Junior or Professional\n",
    "            0,                  # → Junior\n",
    "            self.y - 1          # shift everything above down by 1\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"[JSON] Loaded {len(self.df)} samples | \"\n",
    "            f\"Professional: {(self.df['label'] == 'Professional').sum()} | \"\n",
    "            f\"Unknown: {(self.y == -1).sum()}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b44f52",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7d10563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and prepare data\n",
    "data = Preprocessing_CSV_Seniority(\n",
    "    \"/Users/jonas/Documents/Master_Vorlesungen/Semester_02/Practical Data Science/Final/PDS_Final/data/seniority-v2.csv\"\n",
    ")\n",
    "\n",
    "X = data.X\n",
    "y = data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65663b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train/Test Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acb90104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (7542, 12302)\n",
      "Balanced Shape: (15085, 12302)\n"
     ]
    }
   ],
   "source": [
    "# 3. Train\n",
    "bow = CountVectorizer(ngram_range=(1,2))\n",
    "X_train_vec = bow.fit_transform(X_train)\n",
    "X_test_vec = bow.transform(X_test)\n",
    "\n",
    "ros = RandomOverSampler(random_state=123)\n",
    "X_train_balanced, y_train_balanced = ros.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "print(f\"Original Shape: {X_train_vec.shape}\\nBalanced Shape: {X_train_balanced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aacaf859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best CV score: 0.9956186140968739\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"liblinear\"],\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "\n",
    "logistic_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=logistic_reg,\n",
    "    param_grid=parameters,\n",
    "    cv=5,\n",
    "    scoring=\"f1_weighted\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_balanced, y_train_balanced)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "print(f\"Best params: {grid.best_params_}\")\n",
    "print(f\"Best CV score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93c1c5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9856839872746553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Junior       0.98      1.00      0.99        87\n",
      "      Senior       0.99      1.00      0.99       716\n",
      "        Lead       0.99      0.98      0.99       728\n",
      "  Management       0.96      0.93      0.95       167\n",
      "    Director       0.99      0.99      0.99       188\n",
      "\n",
      "    accuracy                           0.99      1886\n",
      "   macro avg       0.98      0.98      0.98      1886\n",
      "weighted avg       0.99      0.99      0.99      1886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Test on CSV\n",
    "test_csv_prediction = best_model.predict(X_test_vec)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, test_csv_prediction))\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        test_csv_prediction,\n",
    "        target_names=data.label_encoder.categories_[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68aaa15",
   "metadata": {},
   "source": [
    "#### Handling Professional so, dass es klassifiziert wird wenn sich der Klassifikator weniger als 60% sicher auf Junior und Senior ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a0360af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[JSON] Loaded 457 samples | Professional: 154 | Unknown: 0\n",
      "Accuracy: 0.4573304157549234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Junior       0.92      0.07      0.12       164\n",
      "      Senior       0.25      0.82      0.39        39\n",
      "        Lead       0.34      0.71      0.46        97\n",
      "  Management       0.97      0.56      0.71       133\n",
      "    Director       0.55      0.92      0.69        24\n",
      "\n",
      "    accuracy                           0.46       457\n",
      "   macro avg       0.61      0.62      0.48       457\n",
      "weighted avg       0.74      0.46      0.42       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Test on annotated.json\n",
    "annotated_data = Preprocessing_JSON_Seniority(\n",
    "    \"/Users/jonas/Documents/Master_Vorlesungen/Semester_02/Practical Data Science/Final/PDS_Final/data/linkedin-cvs-annotated.json\",\n",
    ")\n",
    "\n",
    "X_test_json = bow.transform(annotated_data.X)\n",
    "y_json_reduced = annotated_data.y_reduced\n",
    "prediction_json = best_model.predict(X_test_json)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_json_reduced, prediction_json))\n",
    "print(classification_report(y_json_reduced, prediction_json, target_names=data.label_encoder.categories[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50802d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = best_model.predict_proba(X_test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf48fb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Professional: 30\n",
      "True Professional: 154\n"
     ]
    }
   ],
   "source": [
    "def predict_with_professional(prob_row, threshold=0.85):\n",
    "    max_prob = np.max(prob_row)\n",
    "    reduced_class = np.argmax(prob_row)\n",
    "\n",
    "    # Junior (0) or Senior (1) AND low confidence → Professional\n",
    "    if reduced_class in [0,1,2,3,4] and max_prob < threshold:\n",
    "        return 1  # Professional (FULL space)\n",
    "\n",
    "    # Otherwise map reduced → full\n",
    "    # reduced: 0,1,2,3,4\n",
    "    # full:    0,2,3,4,5\n",
    "    return reduced_class + 1 if reduced_class >= 1 else 0\n",
    "\n",
    "y_pred_full = np.array(\n",
    "    [predict_with_professional(p) for p in probabilities]\n",
    ")\n",
    "# Wie oft wurde Professional vorhergesagt?\n",
    "print(\"Predicted Professional:\", np.sum(y_pred_full == 1))\n",
    "\n",
    "# Wie oft ist Professional tatsächlich vorhanden?\n",
    "print(\"True Professional:\", np.sum(annotated_data.y == 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f7a2f087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Junior       0.27      0.30      0.29        10\n",
      "Professional       0.10      0.02      0.03       154\n",
      "      Senior       0.27      0.82      0.40        39\n",
      "        Lead       0.36      0.70      0.48        97\n",
      "  Management       0.97      0.52      0.68       133\n",
      "    Director       0.53      0.83      0.65        24\n",
      "\n",
      "    accuracy                           0.43       457\n",
      "   macro avg       0.42      0.53      0.42       457\n",
      "weighted avg       0.45      0.43      0.38       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_names = [\n",
    "    \"Junior\",\n",
    "    \"Professional\",\n",
    "    \"Senior\",\n",
    "    \"Lead\",\n",
    "    \"Management\",\n",
    "    \"Director\"\n",
    "]\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        annotated_data.y,\n",
    "        y_pred_full,\n",
    "        target_names=label_names,\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1e1804e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_Junior</th>\n",
       "      <th>Pred_Professional</th>\n",
       "      <th>Pred_Senior</th>\n",
       "      <th>Pred_Lead</th>\n",
       "      <th>Pred_Management</th>\n",
       "      <th>Pred_Director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True_Junior</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_Professional</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_Senior</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_Lead</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_Management</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>69</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_Director</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Pred_Junior  Pred_Professional  Pred_Senior  Pred_Lead  \\\n",
       "True_Junior                  3                  1            2          4   \n",
       "True_Professional            7                  3           55         89   \n",
       "True_Senior                  0                  1           32          5   \n",
       "True_Lead                    1                  3           23         68   \n",
       "True_Management              0                 20            8         19   \n",
       "True_Director                0                  2            0          2   \n",
       "\n",
       "                   Pred_Management  Pred_Director  \n",
       "True_Junior                      0              0  \n",
       "True_Professional                0              0  \n",
       "True_Senior                      0              1  \n",
       "True_Lead                        2              0  \n",
       "True_Management                 69             17  \n",
       "True_Director                    0             20  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    annotated_data.y,\n",
    "    y_pred_full,\n",
    "    labels=list(range(len(label_names)))\n",
    ")\n",
    "\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f\"True_{l}\" for l in label_names],\n",
    "    columns=[f\"Pred_{l}\" for l in label_names]\n",
    ")\n",
    "\n",
    "cm_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
